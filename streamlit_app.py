# ______________________________________________________________________________________________________
# Import des biblioth√®ques
# ______________________________________________________________________________________________________

import pandas as pd
import seaborn as sns
import numpy as np
import pandas as pd
import pickle

import streamlit as st
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from joblib import dump, load
from datetime import datetime

from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report
from sklearn import linear_model, neighbors, svm, tree, ensemble
from sklearn.model_selection import GridSearchCV, train_test_split

# ______________________________________________________________________________________________________
# Configuration du site
# ______________________________________________________________________________________________________

st.set_page_config(page_title="JAD'Up",  layout='wide', page_icon='Agence de Marketing.ico')

st.sidebar.title("Sommaire")
st.sidebar.image('Agence de Marketing.ico')

pages = ["üìã Introduction au jeu de donn√©es",
         "üìä Analyse",
         "üß™ Preprocessing",
         "üîÆ Challenge de mod√®les",
         "üîç Interpr√©tabilit√©",
         "‚öôÔ∏è Personnaliser votre campagne"]

page = st.sidebar.radio("Aller vers", pages) 


# ______________________________________________________________________________________________________
# Import du jeu de donn√©es et des mod√®les √† utiliser
# ______________________________________________________________________________________________________

df = pd.read_csv('bank.csv', sep = ',')
rlc = load('Regression logistique.joblib')
knn = load('K plus proches voisins.joblib')
dtc = load('Decision Tree Classifier.joblib')
rfc = load('Random Forest Classifier.joblib')
compare = pd.read_csv('compare_scores.csv', sep = ',')

rlc_accuracy=compare.iloc[0]["accuracy"]
knn_accuracy=compare.iloc[1]["accuracy"]
dtc_accuracy=compare.iloc[2]["accuracy"]
rfc_accuracy=compare.iloc[3]["accuracy"]

rlc_precision=compare.iloc[0]["precision"]
knn_precision=compare.iloc[1]["precision"]
dtc_precision=compare.iloc[2]["precision"]
rfc_precision=compare.iloc[3]["precision"]

rlc_rappel=compare.iloc[0]["rappel"]
knn_rappel=compare.iloc[1]["rappel"]
dtc_rappel=compare.iloc[2]["rappel"]
rfc_rappel=compare.iloc[3]["rappel"]

filename_expl = 'explainer.sav'
#load_explainer = pickle.load(open(filename_expl, 'rb'))

filename = 'shapvalues.sav'
#load_shap_values = pickle.load(open(filename, 'rb'))

# ______________________________________________________________________________________________________
# Pr√©paration des jeux de donn√©es √† utiliser
# ______________________________________________________________________________________________________

df2 = df.copy()
# Creation de tranches d'√¢ges
df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])
# Creation de tranches de solde compte bancaire = balance
df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])
# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])
# Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')
# Cr√©ation de tranches en fonction du d√©lai √©coul√©
df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])
# Creation de tranches de nombre de contact avant la campagne
df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])
# Suppression des colonnes dummies"√©es"
drop_cols=['age','balance','duration','campaign','pdays','previous']
df2 = df2.drop(drop_cols, axis=1)
# Cr√©ation de dummies
var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
df2= df2.join(pd.get_dummies(df2[var], prefix=var))
df2 = df2.drop(df2[var], axis=1)
# Transformation en num√©rique
le = LabelEncoder()
df2['job2']= le.fit_transform(df2['job'])
df2 = df2.drop(['job'], axis=1)
# Remplace yes/no par 1/0
var = ["default", "housing","loan","deposit","contact_last_campaign"]
df2[var] = df2[var].replace(('yes', 'no'), (1, 0))

# ---------- Split jeu entrainement et jeu de test -----------

# Isoler les features de la target
target = df2['deposit']
feats = df2.drop(['deposit'], axis=1)

# S√©paration des donn√©es en jeu d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25, random_state=123)

# Normaliser les donn√©es - MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Regression logistique
rlc_y_pred = rlc.predict(X_test)
probs_rlc = rlc.predict_proba(X_test)
fpr_rlc, tpr_rlc, seuils = roc_curve(y_test, probs_rlc[:,1])
roc_auc_rlc = auc(fpr_rlc, tpr_rlc)

# K plus proches voisins
knn_y_pred = knn.predict(X_test)
probs_knn = knn.predict_proba(X_test)
fpr_knn, tpr_knn, seuils = roc_curve(y_test, probs_knn[:,1])
roc_auc_knn = auc(fpr_knn, tpr_knn)

# Decision Tree
dtc_y_pred = dtc.predict(X_test)
probs_dtc = dtc.predict_proba(X_test)
fpr_dtc, tpr_dtc, seuils = roc_curve(y_test, probs_dtc[:,1])
roc_auc_dtc = auc(fpr_dtc, tpr_dtc)

# Random Forest
rfc_y_pred = rfc.predict(X_test)
probs_rfc = rfc.predict_proba(X_test)
fpr_rfc, tpr_rfc, seuils = roc_curve(y_test, probs_rfc[:,1])
roc_auc_rfc = auc(fpr_rfc, tpr_rfc)


# ---------- Jeu de donn√©es modifi√© -----------

feats_modif=feats.copy()
for month in ['month_jan', 'month_feb','month_mar', 'month_apr', 'month_may','month_jun', 'month_jul','month_aug', 'month_sep','month_oct', 'month_nov','month_dec']:
  feats_modif[month]=0
for duration in ["t_duration_1", "t_duration_2", "t_duration_3", "t_duration_4"]:
  feats_modif[duration]=0

# ---------- Fonction de description -----------

def describe_df(df):
    """
    Fonction am√©lior√©e de description des colonnes, elle permet d'identifier :
    le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de r√©partition des valeurs
    INPUT : le dataframe
    OUTPUT : tableau d'analyse
    """
    res = pd.DataFrame(index=["Name","Type", "Nan", "Unique","Min","Max","Values","Pourcentage"])
    for col in df.columns:
        df_col = df[col]
        res[col] = [
            df_col.name,
            df_col.dtype,
            df_col.isnull().sum(),
            len(df_col.unique()),
            df_col.min(),
            df_col.max(),
            df_col.unique(),
            (df_col.value_counts(ascending=False, normalize=True) * 100)
                .apply(int)
                .to_json(),
        ]
    return res.T


# ______________________________________________________________________________________________________
# 1/ Introduction au jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[0]: 

  st.title("üìã Description du jeu de donn√©es")

  st.markdown("""
           Ce jeu de donn√©es est compos√© de donn√©es personnelles sur des clients d‚Äôune banque qui ont √©t√© ‚Äút√©l√©market√©s‚Äù pour souscrire √† un produit
           que l‚Äôon appelle un 'd√©p√¥t √† terme'.  
           Lorsqu‚Äôun client souscrit √† ce produit, il place une quantit√© d‚Äôargent dans un compte sp√©cifique et ne pourra pas toucher ces fonds avant l‚Äôexpiration
           du terme.  
           En √©change, le client re√ßoit des int√©r√™ts de la part de la banque √† la fin du terme. 
           Le jeu de donn√©es est t√©l√©chargeable au lien suivant :
           https://www.kaggle.com/janiobachmann/bank-marketing-dataset
           """)
         
# ---------- Les chiffres cl√©s -----------

  st.header("Les chiffres cl√©s :")
  col1, col2, col3, col4, col5, col6 = st.columns(6)
  col1.write('')
  col2.metric("Nombre de clients", "11 162")
  col3.metric("Nombre de features", "16")
  col4.metric("Variable cible", "deposit")
  col5.metric("Proportion de r√©ponses positives", "47%")
  col6.write('')
         
# ---------- les variables  -----------

  st.header("Description des variables :")         
  st.image("Describe.png")

  #var = pd.DataFrame({"Nom des variables": ["age","job","marital","education","default","balance","housing","loan","contact","day","month","duration","campaign","pdays","previous","poutcome","deposit"],
  #  "Description": ["Age du client","Profession","Statut marital","Niveau d'√©tudes","D√©faut de paiement","Solde du compte","Pr√™t immo","Pr√™t perso",
  #  "Type de contact","Dernier jour de contact","Dernier mois de  contact","Dur√©e du contact (secondes)","Nombre de contacts","Nb jours √©coul√©s depuis le dernier contact","Nb de contacts",
  #  "R√©sultat de la campagne pr√©c√©dente","R√©sultat de la campagne en cours"]
  #  })

  #st.write(var)

# ---------- Aper√ßu -----------

  code_view = st.checkbox("Aper√ßu du code de la fonction de description")
  if code_view:
    code = ''' 
         def describe_df(df):
             """
             Fonction am√©lior√©e de description des colonnes, elle permet d'identifier :
             le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de r√©partition des valeurs
             INPUT : le dataframe
             OUTPUT : tableau d'analyse
             """
             res = pd.DataFrame(index=["Name","Type", "Nan", "Unique","Min","Max","Values","Pourcentage"])
             for col in df.columns:
                 df_col = df[col]
                 res[col] = [
                     df_col.name,
                     df_col.dtype,
                     df_col.isnull().sum(),
                     len(df_col.unique()),
                     df_col.min(),
                     df_col.max(),
                     df_col.unique(),
                     (df_col.value_counts(ascending=False, normalize=True) * 100)
                         .apply(int)
                         .to_json(),
                 ]
             return res.T
    '''
    st.code(code, language='python')
         
  describe = st.checkbox("Aper√ßu du jeu de donn√©es")
  if describe:
    st.write(df)

# ---------- Ce qu'il faut comprendre -----------

  st.header("Ce qu'il faut retenir :")
  st.markdown("""
           On remarque que certaines variables sont la r√©sultante de la campagne en cours : 
           * contact
           * day
           * month
           * duration
           * campaign
           La variable **deposit** est notre variable cible.
           """)
         
# ______________________________________________________________________________________________________
# 2/ Analyse du jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[1]: 

  st.title("üìä Analyse du jeu de donn√©es")
  st.markdown("""
           L‚Äôanalyse descriptive est le terme donn√© √† l‚Äôanalyse des donn√©es permettant de d√©crire et de r√©sumer des donn√©es historiques de mani√®re significative
           afin que des **insights** en ressortent.  
           L‚Äôanalyse descriptive de notre jeu de donn√©es va nous fournir les informations de base sur les variables, leur r√©partition, et leurs relations potentielles.  
           Nous allons pouvoir observer - _√† premi√®re vue_ - les √©l√©ments qui ont favoris√©, ou √† l'inverse d√©favoris√©, la performance de la campagne commerciale.
           """)

  st.write(" ")

# ---------- Les distributions par type de variables -----------

  st.subheader("Les distributions par type de variables")
         
  col1, col2 = st.columns(2)
  col1.subheader("Variables num√©riques")
  col2.subheader("Variables cat√©gorielles")
  df2 = df.copy()
  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns
  categoricals= df2.select_dtypes(include=['object','category']).columns

# variables num√©riques

  tab1, tab2 = col1.tabs(["üìà Chart", "üìã Describe"])
         
  option = tab1.selectbox("Choix une variable num√©rique :", numerics, index=3)
  hist = px.histogram(df2,x=option,color="deposit",barmode="group", color_discrete_sequence=px.colors.qualitative.Plotly)
  tab1.plotly_chart(hist)
         
  describe= df2[numerics].describe().transpose()
  tab2.write(describe)

  if option=="age":
    col1.info("Les √¢ges extr√™mes semblent avoir une plus forte adh√©rence avec la campagne.")
  elif option=="duration":
    col1.info("On remarque que plus la dur√©e de contact augmente et plus les clients semblent souscrire √† la campagne.")

# variables cat√©gorielles

  tab3, tab4 = col2.tabs(["üìà Chart", "üìã Describe"])

  option = tab3.selectbox("Choix une variable cat√©gorielle :", categoricals, index=7)
  hist = px.histogram(df2,y=option,color="deposit",barmode="group", color_discrete_sequence=px.colors.qualitative.Plotly)
  tab3.plotly_chart(hist)
         
  describe= df2[categoricals].describe().transpose()
  tab4.write(describe)

  if option=="marital":
    col2.info("Le statut marital 'single' semble rendre plus favorable la campagne.")
  elif option=="housing":
    col2.info("L'absence de pr√™t immo semble augmenter les chances de r√©pondre favorablement √† la campagne.")
  elif option=="month":
    col2.info("On observe que certains mois comme Mars, Septembre et Octobre semblent plus propices √† la performance de la campagne."
              "\n A l'inverse les mois de Mai √† Aout semblent diminuer les chances de concr√©tisation. ")
  elif option=="poutcome":
    col2.info("Les clients ayant r√©pondu positivement √† la campagne pr√©c√©dente sont les plus susceptibles de renouveller un d√©p√¥t.")

# ---------- Les correlations -----------

  st.header("Analyse des corr√©lations")
  tab1, tab2 = st.tabs(["‚ñ© Matrice", "üìà Chart"])
         
# Matrice de correlation

  col1, col2 = tab1.columns((2, 1))

  le = LabelEncoder()
  df2=df.copy()
  for col in df2.columns:
    df2[col]= le.fit_transform(df2[col])
         
  heatmap = px.imshow(df2.corr(), color_continuous_scale='RdBu_r')
  heatmap.update_layout(height=600, width=700)
  col1.plotly_chart(heatmap)    

# Corr√©lations directes

  col3, col4 = tab2.columns((3, 1))

  corr=pd.DataFrame(df2.corr()["deposit"])
  corr=corr.sort_values("deposit",ascending=False)
  corr=corr.drop('deposit')
         
  fig = px.bar(corr, y='deposit', x=corr.index, color="deposit", color_continuous_scale='Bluered_r')
  fig.update_layout(height=500, width=1000)
  col3.plotly_chart(fig)  

# Corr√©lations coefficients

  col4.write(corr)


# ---------- Les observations -----------

  st.header("Observations")
  st.info("""
           On remarque que 8 324 clients n'ont pas √©t√© contact√©s lors de la campagne pr√©c√©dente.
           Lorsque PREVIOUS = 0 alors PDAYS = -1
           """)
  st.info("""
           Dans l'ordre, les variables les plus corr√©l√©es (valeur absolue) avec la target _[deposit]_ sont :
           * **_duration_** = Dur√©e du contact (en secondes)
           * **_contact_** = Type de contact 
           * housing = Pr√™t immo
           * previous = Nb contacts au cours de la campagne pr√©c√©dente
           * housing = pdays = Nb jours √©coul√©s depuis le dernier contact de la campagne pr√©c√©dente
           * previous = balance = Solde compte bancaire
           **Attention** , les **_deux variables_** correspondent √† des donn√©es non connues √† priori (avant lancement de la campagne)
           """)
         
# ______________________________________________________________________________________________________
# 3/ Pr√©processing
# ______________________________________________________________________________________________________

if page==pages[2]: 

  st.title("üß™ Pr√©processing - Mod√®les pr√©dictifs")


# ---------- Le pr√©processing, √ßa sert √† quoi -----------

  expander1 = st.expander("Le pr√©processing, √ßa sert √† quoi ?")

  expander1.markdown("""
           Le pr√©processing est une de composante essentielle de la data science.
           Cette √©tape d√©crit toutes les **transformations** effectu√©es sur le jeu de donn√©es initial et indispensables √† la cr√©ation du mod√®le d'apprentissage fiable et robuste.  
           Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les donn√©es sont pr√©sent√©es dans un format qui met en √©vidence les aspects pertinents requis pour r√©soudre un probl√®me.  
           Les fonctions de pr√©processing consistent √† **restructurer** les donn√©es brutes sous une forme adapt√©e √† des types particuliers d'algorithmes.  Les √©tapes sont :
           * la transformation des donn√©es,
           * la r√©duction des donn√©es,
           * la s√©lection des variables
           * et √† la mise √† l'√©chelle.
           """)
  
  expander1.image('preprocessing.JPG', caption='Les √©tapes de pr√©processing')     


# ---------- Les √©tapes de pr√©processing -----------

  st.header("Les √©tapes de pr√©processing appliqu√©es :")

# Variables num√©riques

  st.subheader("Le traitement des variables num√©riques")
  code = ''' 
    # Creation de tranches d'√¢ges
    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])

    # Creation de tranches de solde compte bancaire = balance
    df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')

    # Cr√©ation de tranches en fonction du d√©lai √©coul√©
    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])

    # Creation de tranches de nombre de contact avant la campagne
    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Suppression des colonnes dummies"√©es"
    drop_cols=['age','balance','duration','campaign','pdays','previous']
    df2 = df2.drop(drop_cols, axis=1)
    '''
  st.code(code, language='python')

# Variables cat√©gorielles

  st.subheader("Le traitement des variables cat√©gorielles")
  code = ''' 
    # Cr√©ation de dummies
    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
    df2= df2.join(pd.get_dummies(df2[var], prefix=var))
    df2 = df2.drop(df2[var], axis=1)

    # Transformation en num√©rique
    le = LabelEncoder()
    df2['job2']= le.fit_transform(df2['job'])
    df2 = df2.drop(['job'], axis=1)

    # Remplace yes/no par 1/0
    var = ["default", "housing","loan","deposit","contact_last_campaign"]
    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))
    '''
  st.code(code, language='python')

         
# ---------- Jeu de donn√©es final -----------

  st.header("Le jeu de donn√©es final :")
  st.write(df2)
         
# ---------- Arbre de correlations apr√®s preprocessing -----------

  st.header("Arbre de correlations apr√®s preprocessing :")

  corr=pd.DataFrame(df2.corr()["deposit"])
  corr=corr.sort_values("deposit",ascending=False)
  corr=corr.drop('deposit')
         
  fig = px.bar(corr, y='deposit', x=corr.index, color="deposit", color_continuous_scale='Bluered_r')
  fig.update_layout(height=500, width=1000).update_layout(height=700, width=1000)
  st.plotly_chart(fig)  


# ---------- Les enseignements -----------

  st.header("Les observations :")
  st.info("""
           On voit clairement que la feature **[duration]** impacte positivement la campagne d√®s lors que la valeur est √©lev√©e (temps de contact).  
           A l'inverse, une dur√©e courte se traduit par une forte corr√©lation n√©gative.  
           Egalement, les clients ayant r√©pondu favorablement √† la campagne pr√©c√©dente **[poutcome]** semblent √™tre les plus susceptibles de renouveler leur action.  
           Les mois de mars et octobre [month] semblent √™tre les meilleurs mois pour optimiser les leads.
           """)


# ______________________________________________________________________________________________________
# 4/ Challenge de mod√®les
# ______________________________________________________________________________________________________

if page==pages[3]:
                 
  st.title("üîÆ Mod√®les pr√©dictifs")
  st.markdown("""
              Les quatre mod√®les pr√©dictifs suivants ont √©t√© choisis en raison de leur √©quilibre entre bonne performance et dur√©e d'ex√©cution sur ce jeu de donn√©es.
              * La **r√©gression logistique** ou LRC
              * Le mod√®le **K-plus proches voisins** ou KNN
              * L'**arbre de d√©cision** ou DTC
              * Les **for√™ts al√©atoires** ou RFC 
              """)
  st.write("  ")

# ---------- Les 3 mod√®les -----------

  col1, col2, col3, col4 = st.columns(4)
                  
# R√©gression logistique -----------------------------------------------------------------------

  with col1:
    st.subheader("Mod√®le LRC")
    st.image("regression-lineaire.png")
        
    st.metric("Accuracy", "{:.2%}".format(rlc_accuracy))
    st.metric("Precision", "{:.2%}".format(rlc_precision))
    st.metric("Rappel", "{:.2%}".format(rlc_rappel))

    st.write("Matrice de confusion :")     
    st.write(pd.crosstab(y_test, rlc_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))     
    #heatmap = px.imshow(pd.crosstab(y_test, rlc_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))
    #heatmap.update_layout(height=300, width=300)
    #st.plotly_chart(heatmap) 

         
# K plus proche voisins -----------------------------------------------------------------------

  with col2:
    st.subheader("Mod√®le KNN")
    st.image("networking.png")

    st.metric("Accuracy", "{:.2%}".format(knn_accuracy))
    st.metric("Precision", "{:.2%}".format(knn_precision))
    st.metric("Rappel", "{:.2%}".format(knn_rappel))

    st.write("Matrice de confusion :")            
    st.write(pd.crosstab(y_test, knn_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))     
    #heatmap = px.imshow(pd.crosstab(y_test, knn_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))
    #heatmap.update_layout(height=300, width=300)
    #st.plotly_chart(heatmap) 
     
# Arbre de d√©cision -----------------------------------------------------------------------

  with col3:
    st.subheader("Mod√®le DTC")
    st.image("arbre-de-decision.png")

    st.metric("Accuracy", "{:.2%}".format(dtc_accuracy))
    st.metric("Precision", "{:.2%}".format(dtc_precision))
    st.metric("Rappel", "{:.2%}".format(dtc_rappel))

    st.write("Matrice de confusion :")        
    st.write(pd.crosstab(y_test, dtc_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))     
    #heatmap = px.imshow(pd.crosstab(y_test, dtc_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))
    #heatmap.update_layout(height=300, width=300)
    #st.plotly_chart(heatmap) 

# Random Forest -----------------------------------------------------------------------

  with col4:
    st.subheader("Mod√®le RFC")
    st.image("foret.png")

    st.metric("Accuracy", "{:.2%}".format(rfc_accuracy))
    st.metric("Precision", "{:.2%}".format(rfc_precision))
    st.metric("Rappel", "{:.2%}".format(rfc_rappel))

    st.write("Matrice de confusion :")        
    st.write(pd.crosstab(y_test, rfc_y_pred, rownames=['R√©el OUI', 'R√©el NON'], colnames=['Pr√©dit NON', 'Pr√©dit OUI']))     
    #heatmap = px.imshow(pd.crosstab(y_test, rfc_y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))
    #heatmap.update_layout(height=300, width=300)
    #st.plotly_chart(heatmap) 


# Comparaison des r√©sultats -----------------------------------------------------------------------

  st.write(" ")
  
  tab1, tab2 = st.columns(2)

  #Graphique de comparaison des r√©sultats
  tab1.subheader("üìä Graphique de comparaison")
  fig = plt.figure(figsize=(20,6))
  bar = px.bar(compare, x="Model", y=['accuracy', 'precision', 'rappel','roc'], barmode='group', color_discrete_sequence=px.colors.qualitative.Plotly)
  bar.add_hline(y=0.80, line_width=3, line_dash="dash", line_color="black")
  tab1.plotly_chart(bar)     

  # Comparaison avec l'indice des ROC
  tab2.subheader("üìà Courbe ROC")
  import plotly.graph_objects as go         
  fig = go.Figure(data=go.Scatter(x=fpr_rlc, y=tpr_rlc , mode='lines', name='Mod√®le LCR (auc = %0.2f)' % roc_auc_rlc))
  fig.add_trace(go.Scatter(x=fpr_knn, y=tpr_knn , mode='lines', name='Mod√®le KNN (auc = %0.2f)' % roc_auc_knn))
  fig.add_trace(go.Scatter(x=fpr_dtc, y=tpr_dtc , mode='lines', name='Mod√®le DTC (auc = %0.2f)' % roc_auc_dtc))
  fig.add_trace(go.Scatter(x=fpr_rfc, y=tpr_rfc , mode='lines', name='Mod√®le RFC (auc = %0.2f)' % roc_auc_rfc))
  fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name='Al√©atoire (auc = 0.5)', line = dict(color='black', width=2, dash='dot')))
  fig.update_layout(height=450, width=700, legend=dict(yanchor="top", y=0.5, xanchor="left", x=0.65))
  tab2.plotly_chart(fig)          
         
  with tab2.expander("Plus d'explication sur ce graphique :"):
    st.write("""
         La courbe ROC (pour **Receiver Operating Characteristic**) est une courbe qui repr√©sente le comportement de notre classifieur √† deux classes pour tous les seuils de d√©tection possibles.
         \n Si nous utilisons les probabilit√©s d‚Äôappartenance √† la classe cible renvoy√©es par notre classifieur au lieu des pr√©dictions,
         nous pourrions choisir librement √† partir de quelle probabilit√© nous consid√©rons qu‚Äôun item est de cette classe.
         \n En prenant des seuils de 0 √† 1 (ou 100%), nous balayons **toutes les possibilit√©s**.
         \n A chaque seuil, nous pouvons calculer le taux de vrais positifs et le taux de faux positifs.
         \n La courbe ROC repr√©sente ces r√©sultats avec le taux de faux positifs sur l‚Äôaxe x et le taux de vrais positifs sur l‚Äôaxe y.
     """)

  st.subheader("üèÜ Le mod√®le gagnant")
  st.success("Le mod√®le **Random Forest** obtient les meilleures performances et semble le plus √©quilibr√©. Il permet de maximiser les positifs.")

         
 # ______________________________________________________________________________________________________
# 5/ INTERPRETABILITE
# ______________________________________________________________________________________________________

if page==pages[4]: 

  st.title("üîç Interpr√©tabilit√© du mod√®le Random Forest")
  st.markdown("""
              L‚Äôinterpr√©tabilit√© et l'explicabilit√© d‚Äôun syst√®me de data science sont fondammentales.
              Il s'agit de chercher √† rendre un mod√®le intelligible, √† l‚Äôexpliquer et √† le commenter.  
              L‚Äô**Interpr√©tabilit√©** consiste √† pouvoir comprendre comment le mod√®le fonctionne en fournissant des informations sur le mod√®le de Machine Learning
              ainsi que sur les donn√©es utilis√©es. L‚Äôinterpr√©tabilit√© est d√©di√©e aux experts en ML ou des donn√©es.  
              L‚Äô**Explicabilit√©** consiste √† pouvoir expliquer pourquoi le mod√®le a donn√© telle pr√©diction en fournissant une information dans un format s√©mantique
              complet et accessible √† un utilisateur n√©ophyte ou technophile.  
              \n
              Ici nous utiliserons la m√©thode d‚Äôinterpr√©tabilit√© dont nous allons expliciter le fonctionnement ainsi que ses points positifs et n√©gatifs : **SHAP** !
           """) 
         
# ______________________________________________________________________________________________________
# 6/ BONUS
# ______________________________________________________________________________________________________

if page==pages[5]: 

  st.title("‚öôÔ∏è Personnaliser votre campagne")
  st.write(" ")
  st.warning("""
        Cette partie va vous permettre de simuler la performance d'une future campagne en fonction de param√®tres tels que le mois de lancement ou la dur√©e
        de l'appel t√©l√©phonique.  
        Ce concept repose sur le r√©-entrainement du mod√®le pr√©dictif avec un jeu de donn√©es modifi√© compte tenu des param√®tres s√©lectionn√©s.  
        Les autres variables telles que le solde du compte bancaire ou pr√©sence d'un pr√™t immo par exemple restent inchang√©es.  
        Ce module permet d'observer _hypoth√©tiquement_ quels auraient p√ª √™tre les r√©sultats de la campagne de r√©f√©rence si certains param√®tres avaient √©t√© diff√©rents.  
        Les r√©sultats apport√©s sont indicatifs.
        """)
  st.write(" ")

  col1, col2, col3, col4, col5  = st.columns((1, 2 , 1, 2, 1))

# Volet personnalisation de la campagne -----------------------------------------------------------------------

  model = col2.radio(
     "‚ú®Quel mod√®le pr√©dictif souhaitez-vous privil√©gier ?",
     ('R√©gression logistique', 'K-Plus proches voisins', 'Arbre de d√©cisions', 'F√¥rets al√©atoires'), index=3)
  
  seuil = col2.number_input(
      "üéöÔ∏è Quel seuil pour les pr√©dictions ?", min_value=0.1, max_value=0.9, value=0.5)         
         
  m = col4.select_slider(
     'üìÖ Quel est le mois pr√©visionnel de lancement pour cette campagne ?',
     options=['Janvier', 'F√©vrier','Mars', 'Avril', 'Mai','Juin', 'Juillet', 'Ao√ªt', 'Septembre','Octobre', 'Novembre','D√©cembre'])
         
  d = col4.select_slider(
     "‚åö A combien de minutes estimez-vous la dur√©e d'un appel t√©l√©phonique pour cette campagne ?",
     options=["1:00", "2:00", "3:00", "4:00", "5:00", "6:00", "7:00", "8:00", "9:00", "10:00"], value="5:00")
   
  st.write(" ")
  st.write(" ")

# Volet entrainement du mod√®le de la campagne -----------------------------------------------------------------------

  col6, col7, col8  = st.columns(3)

  if col7.button('Lancer la pr√©diction'): 
    feats_modif_x=feats_modif.copy()

    # Choix du mod√®le -----------------------------------
    if model == "R√©gression logistique":
      classifieur = rlc
      accuracy=rlc_accuracy
    elif model == "K-Plus proches voisins":
      classifieur = knn
      accuracy=knn_accuracy
    elif model == "Arbre de d√©cisions":
      classifieur = dtc
      accuracy=dtc_accuracy
    else:
      classifieur = rfc
      accuracy=rfc_accuracy

    # Choix du mois -----------------------------------
    if m == "Janvier":
      feats_modif_x["month_jan"]=1
    elif m == "F√©vrier":
      feats_modif_x["month_feb"]=1
    elif m == "Mars":
      feats_modif_x["month_mar"]=1
    elif m == "Avril":
      feats_modif_x["month_apr"]=1
    elif m == "Mai":
      feats_modif_x["month_may"]=1
    elif m == "Juin":
      feats_modif_x["month_jun"]=1
    elif m == "Juillet":
      feats_modif_x["month_jul"]=1
    elif m == "Ao√ªt":
      feats_modif_x["month_aug"]=1
    elif m == "Septembre":
      feats_modif_x["month_sep"]=1
    elif m == "Octobre":
      feats_modif_x["month_oct"]=1
    elif m == "Novembre":
      feats_modif_x["month_nov"]=1
    else:
      feats_modif_x["month_dec"]=1

    # Choix de la dur√©e -----------------------------------
    if d in ["1:00","2:00"]:
      feats_modif_x["t_duration_1"]=1
    elif d in ["3:00","4:00"]:
      feats_modif_x["t_duration_2"]=1    
    elif d in ["4:00","5:00","6:00","7:00"]:
      feats_modif_x["t_duration_3"]=1                  
    else:
      feats_modif_x["t_duration_4"]=1    

    # Entrainement du mod√®le choisi -----------------------------------
         
    col7.write(classifieur)
    col7.write(" ")  
         
    y_pred = classifieur.predict(feats_modif_x)
    probas=classifieur.predict_proba(feats_modif_x)
    probas=pd.DataFrame(probas, columns=['NO','Probabilit√©s'], index=feats_modif_x.index)
    probas = probas.drop(['NO'], axis=1)
    probas['Classification'] = np.where(probas['Probabilit√©s']>seuil,1,0)         

    col9, col10, col11  = st.columns(3)

    col9.write(" ") 
    col9.subheader("Distribution des probabilit√©s")
    fig = px.histogram(probas,x="Probabilit√©s",color="Classification", nbins=100, color_discrete_sequence=px.colors.qualitative.Pastel1)
    fig.add_vline(x=seuil, line_width=3, line_dash="dash", line_color="black")
    fig.update_layout(height=400, width=500, legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.99))
    col9.plotly_chart(fig) 
         
    col10.write(" ") 
    col10.subheader("R√©partition des pr√©dictions")
    pie = px.pie(probas['Classification'].value_counts(), values='Classification', names='Classification', hole=.4, color_discrete_sequence=px.colors.qualitative.Pastel1)
    pie.update_layout(height=400, width=400, legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.99))
    col10.plotly_chart(pie)

    col11.write(" ")
    col11.subheader("Chiffres cl√©s")

    col11.metric("Nombre de clients scor√©s positifs", sum(probas['Classification']), sum(probas['Classification'])-5289)  
    col11.metric("Performance pr√©sum√©e de la campagne *", "{:.2%}".format(sum(probas['Classification'])/11162), "{:.2%}".format(sum(probas['Classification'])/11162-0.47))  
    col11.metric("Score du mod√®le s√©lectionn√© **", "{:.2%}".format(accuracy), "{:.2%}".format(accuracy-rfc_accuracy)) 
         
    st.info("""
        - *Performance : Pourcentage estim√© de clients susceptibles d'effectuer un d√©p√¥t lors de la campagne.
        - **Score du mod√®le : Taux de pr√©dictions correctes effectu√©es par le mod√®le choisi. Le mod√®le Random Forest est utilis√© comme r√©f√©rence.
        """)

    st.write(" ")
    st.subheader("üèÜ La combinaison gagnante")
    st.success("""
        La meilleure combinaison de param√®tres semble √™tre la suivante : \n
        - Dur√©e d'appel sup√©rieure √† **8 min**
        - Lancement au cours du mois d'**octobre**
        """)
